## 爬虫 + ETL 工作流 Admin 方案

### 架构设计
```
Crawler/ETL (Celery) → Neo4j (状态机) → Admin 审核 → Production 查询
```

### 核心组件

**1. 任务调度层**
- **Celery + Redis**: 异步执行爬虫/ETL 任务，支持重试和优先级[1][2]
- **Flower Web UI** (`localhost:5555`): 实时监控任务进度、Worker 状态、任务历史[3]

**2. 数据审核层（自定义 FastAPI Admin）**
- **FastAPI + HTMX + Jinja2**: 轻量级审核界面，无需独立前端框架
- 展示 `status=needs_review` 的数据，提供 Approve/Reject/Edit 操作
- 通过 HTMX 实现无刷新交互

**3. 数据状态机（Neo4j）**
```
raw → validated → needs_review → approved → production
                              ↓
                          rejected
```

**4. 审计血缘**
- Neo4j 关系记录所有修改：`(record)-[:MODIFIED_BY {timestamp, user, reason, old_value, new_value}]->(audit)`

### 工作流
1. Celery 任务爬取 → 写入 Neo4j (`status=raw`)
2. ETL 校验 → 异常标记 `needs_review`
3. Admin 页面人工修正 → 更新 `approved` + 记录 provenance
4. GraphQL 查询仅返回 `status=approved` 数据

### 技术优势
- 无需 Django Admin 重量级依赖
- 与现有 FastAPI + Neo4j 架构一致
- Flower 开箱即用，Celery 生态成熟[4][1]

[1](https://testdriven.io/blog/fastapi-and-celery/)
[2](https://blog.stackademic.com/using-celery-rabbitmq-with-fastapi-2e6f0236841e)
[3](https://github.com/dkhubs/fastapi-flower)
[4](https://derlin.github.io/introduction-to-fastapi-and-celery/03-celery/)
# BRN-005.schema: 股票 KG / Neo4j 属性图实现
0）我的 admin 需要定制工作流，大概是 爬虫-数据清洗-审核-写库（neo4j） 前三步我感觉用 django 弄简单点。整个写入流，完全由 admin 系统管理。为了简化，你可以只 mock 一下爬虫和 etl，但是要设计好写入方案。
1) 核心理念：知识图谱=结构化事实+语义推理，Neo4j Property Graph 通过节点/关系属性比 RDF SPO 更灵活，支持原生索引与 GDS 算法。
2) RDF vs Property Graph：RDF 仅三元组（SPO），属性需额外节点；Neo4j 节点/关系可直接挂 `{quarter,value}`，事实上下文更直接。
3) 概念映射：
| KG 概念 | 图实现 | 股票示例 |
| --- | --- | --- |
| 实体 | `(:Company {ticker:'AAPL'})` + 多 label | `:Company:TechStock` 支持层次 |
| 关系 | `[:HAS_EPS {quarter:'2024Q1'}]` | 关系属性承载上下文 |
| 属性/事实 | 节点/关系属性或 `(:Fact {value:1.53})` | 静态 props + 时序事实节点 |
| 本体 | Label 层次 + 约束 + APOC 推理 | `Company SUBCLASS_OF FinancialEntity` |
| 事实层 | 多源事实节点 + `[:FROM]` | `(:Quote)<-[:FROM]-(Source)` |
| 推理 | Cypher 多跳 + GDS | `[:COMPETES_WITH*1..2]` |
4) 规模估算（4K 股票、10 年）：
| 节点 | 数量 | 备注 |
| --- | --- | --- |
| `:Company` | 4K | 静态属性 |
| `:DailyQuote` | ≈10M | 日 OHLCV + 向量 |
| `:EarningsReport` | 160K | 季报事实 |
| `:NewsArticle` | 5M | RAG chunk |
| `:DataSource` | 20 | provenance |
| 总计 | ~15M 节点 / 50M 边 | AuraDB Pro 可承载 |
5) 关键关系：`HAS_QUOTE`, `REPORTED`, `HAS_SECTOR`, `COMPETES_WITH`, `MENTIONS`, `PROVENANCE_FROM`, `NEXT_PERIOD`；全部允许属性携带置信度/时间戳。
6) 查询示例：
- EPS 列表：`MATCH (c:Company {ticker:'AAPL'})-[:HAS_EPS]->(f:EpsFact) RETURN f.value ORDER BY f.quarter`.
- 置信加权价：`MATCH (c {ticker:'AAPL'})-[r:HAS_QUOTE]->(q:Quote) RETURN avg(r.confidence*q.close)`.
- 多跳推理：`MATCH (c {ticker:'AAPL'})-[:COMPETES_WITH*1..2]->(peer)-[:HAS_SECTOR]->(:Sector {name:'Tech'}) RETURN peer, avg((peer)-[:HAS_EPS]->(:EpsFact))`.
7) DDL 摘要：唯一约束 `Company(ticker)`, 复合约束 `(DailyQuote.ticker,date)`, 索引 `Company(sector)`, 向量索引 `kg_vec` 覆盖含 `embedding` 的节点。
8) 构建流程：ETL (yfinance/SEC→Cypher MERGE) → Entity Resolution (APOC 相似度) → 丰富事实（LLM 提取新闻 SPO） → 查询层 (GraphQL/REST + 缓存/RAG)。
9) 运维：日增 4K Quote + 新闻批 ETL，Neo4j AuraDB Pro/自建 VPS 需 SSD、定期 GDS 预计算 PageRank/相似嵌入。
10) 目标：交付语义+时序+provenance 的统一股票 KG，为量化、RAG、GDS 推理提供 1-stop schema。
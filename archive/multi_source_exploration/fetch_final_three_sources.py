"""
ä¸‰æºæ•°æ®è·å– + ä¸¥æ ¼ä¸€è‡´æ€§éªŒè¯

æ ¸å¿ƒé€»è¾‘:
1. ä¸‰ä¸ªæ•°æ®æºéƒ½å°è¯•è·å–: yfinance, finnhub, twelvedata/akshare
2. è‡³å°‘2ä¸ªæºçš„æ•°æ®ä¸€è‡´ï¼ˆåœ¨è¯¯å·®èŒƒå›´å†…ï¼‰â†’ âœ… å¯ä¿¡
3. åªæœ‰1ä¸ªæºæˆåŠŸï¼Œæˆ–3ä¸ªæºéƒ½ä¸ä¸€è‡´ â†’ âŒ æ‹’ç»

ä¸€è‡´æ€§å®šä¹‰:
- ä»·æ ¼: Â±5% è¯¯å·®èŒƒå›´
- PE: Â±10% è¯¯å·®èŒƒå›´
- PEG: Â±15% è¯¯å·®èŒƒå›´
"""

import logging
from typing import List, Optional, Dict, Tuple
from datetime import datetime
from dataclasses import asdict

from core.models import StockData
from core.data_io import save_to_csv
from data_collection import fetch_yfinance
from data_collection import fetch_finnhub
from data_collection import fetch_twelvedata
from data_collection import fetch_akshare

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ä¸€è‡´æ€§éªŒè¯çš„è¯¯å·®å®¹å¿åº¦
TOLERANCE = {
    'price': 0.05,      # 5%
    'pe_ratio': 0.10,   # 10%
    'peg_ratio': 0.15,  # 15%
}


def is_value_consistent(v1: Optional[float], v2: Optional[float], tolerance: float) -> bool:
    """
    æ£€æŸ¥ä¸¤ä¸ªå€¼æ˜¯å¦åœ¨è¯¯å·®èŒƒå›´å†…ä¸€è‡´
    
    Args:
        v1, v2: è¦æ¯”è¾ƒçš„ä¸¤ä¸ªå€¼
        tolerance: ç›¸å¯¹è¯¯å·®å®¹å¿åº¦ï¼ˆä¾‹å¦‚ 0.05 = 5%ï¼‰
        
    Returns:
        True if ä¸€è‡´ï¼ŒFalse otherwise
    """
    if v1 is None or v2 is None:
        return False
    
    if v1 == 0 and v2 == 0:
        return True
    
    if v1 == 0 or v2 == 0:
        return False
    
    # è®¡ç®—ç›¸å¯¹è¯¯å·®
    avg = (abs(v1) + abs(v2)) / 2
    diff = abs(v1 - v2)
    relative_error = diff / avg
    
    return relative_error <= tolerance


def count_consistent_pairs(values: List[Optional[float]], tolerance: float) -> int:
    """
    è®¡ç®—æœ‰å¤šå°‘å¯¹å€¼æ˜¯ä¸€è‡´çš„
    
    Args:
        values: å€¼åˆ—è¡¨ï¼ˆå¯èƒ½åŒ…å«Noneï¼‰
        tolerance: è¯¯å·®å®¹å¿åº¦
        
    Returns:
        ä¸€è‡´å¯¹çš„æ•°é‡
    """
    valid_values = [v for v in values if v is not None]
    
    if len(valid_values) < 2:
        return 0
    
    consistent_count = 0
    for i in range(len(valid_values)):
        for j in range(i + 1, len(valid_values)):
            if is_value_consistent(valid_values[i], valid_values[j], tolerance):
                consistent_count += 1
    
    return consistent_count


def find_consistent_value(values: List[Optional[float]], tolerance: float) -> Optional[float]:
    """
    ä»å¤šä¸ªå€¼ä¸­æ‰¾åˆ°ä¸€è‡´çš„å€¼
    
    é€»è¾‘:
    1. å¦‚æœæœ‰è‡³å°‘2ä¸ªå€¼ä¸€è‡´ â†’ è¿”å›å®ƒä»¬çš„å¹³å‡å€¼
    2. å¦åˆ™ â†’ è¿”å›None
    
    Args:
        values: å€¼åˆ—è¡¨
        tolerance: è¯¯å·®å®¹å¿åº¦
        
    Returns:
        ä¸€è‡´çš„å€¼ï¼ˆæˆ–å¹³å‡å€¼ï¼‰ï¼Œæ²¡æœ‰åˆ™è¿”å›None
    """
    valid_values = [v for v in values if v is not None]
    
    if len(valid_values) < 2:
        return None
    
    # æ‰¾åˆ°æœ€å¤§çš„ä¸€è‡´æ€§ç°‡
    for i in range(len(valid_values)):
        consistent_group = [valid_values[i]]
        for j in range(len(valid_values)):
            if i != j and is_value_consistent(valid_values[i], valid_values[j], tolerance):
                consistent_group.append(valid_values[j])
        
        # å¦‚æœæ‰¾åˆ°è‡³å°‘2ä¸ªä¸€è‡´çš„å€¼
        if len(consistent_group) >= 2:
            return sum(consistent_group) / len(consistent_group)
    
    return None


def validate_consistency(sources: List[StockData]) -> Tuple[bool, Dict[str, Optional[float]], str]:
    """
    éªŒè¯å¤šä¸ªæ•°æ®æºçš„ä¸€è‡´æ€§
    
    Args:
        sources: StockDataå¯¹è±¡åˆ—è¡¨
        
    Returns:
        (is_valid, aggregated_values, reason)
        - is_valid: æ˜¯å¦æœ‰è‡³å°‘2ä¸ªæºä¸€è‡´
        - aggregated_values: èšåˆåçš„å€¼
        - reason: éªŒè¯ç»“æœè¯´æ˜
    """
    if len(sources) < 2:
        return False, {}, f"åªæœ‰{len(sources)}ä¸ªæ•°æ®æºæˆåŠŸï¼Œéœ€è¦è‡³å°‘2ä¸ª"
    
    # æå–å„å­—æ®µçš„å€¼
    prices = [s.price for s in sources]
    pes = [s.pe for s in sources]
    pegs = [s.peg for s in sources]
    
    # éªŒè¯ä»·æ ¼ä¸€è‡´æ€§ï¼ˆå¿…é¡»ï¼‰
    consistent_price = find_consistent_value(prices, TOLERANCE['price'])
    if consistent_price is None:
        return False, {}, f"ä»·æ ¼ä¸ä¸€è‡´: {[f'{p:.2f}' if p else 'None' for p in prices]}"
    
    # éªŒè¯PEä¸€è‡´æ€§
    consistent_pe = find_consistent_value(pes, TOLERANCE['pe_ratio'])
    
    # éªŒè¯PEGä¸€è‡´æ€§
    consistent_peg = find_consistent_value(pegs, TOLERANCE['peg_ratio'])
    
    # æ„é€ èšåˆç»“æœ
    aggregated = {
        'price': consistent_price,
        'pe_ratio': consistent_pe,
        'peg_ratio': consistent_peg,
    }
    
    # ç»Ÿè®¡ä¸€è‡´æ€§
    source_names = [s.data_source for s in sources]
    reason = f"âœ… {len(sources)}ä¸ªæºä¸€è‡´: {', '.join(source_names)}"
    
    return True, aggregated, reason


def fetch_from_all_sources(ticker: str) -> List[StockData]:
    """
    ä»æ‰€æœ‰æ•°æ®æºè·å–æ•°æ®
    
    ç­–ç•¥:
    - ç¾è‚¡: yfinance + finnhub + twelvedata
    - æ¸¯è‚¡: yfinance + twelvedata + akshare
    
    Args:
        ticker: è‚¡ç¥¨ä»£ç 
        
    Returns:
        æˆåŠŸè·å–çš„StockDataåˆ—è¡¨
    """
    results = []
    
    # 1. yfinance (å…¨å¸‚åœº)
    logger.info(f"\n{'='*50}")
    logger.info(f"[1/3] yfinance: {ticker}")
    yf_data = fetch_yfinance.fetch_stock_data(ticker)
    if yf_data:
        results.append(yf_data)
        logger.info(f"âœ… yfinanceæˆåŠŸ: price={yf_data.price:.2f}, PE={yf_data.pe}, PEG={yf_data.peg}")
    else:
        logger.warning(f"âŒ yfinanceå¤±è´¥")
    
    # 2. finnhub (ç¾è‚¡ä¼˜å…ˆ)
    logger.info(f"\n{'='*50}")
    logger.info(f"[2/3] finnhub: {ticker}")
    fh_data = fetch_finnhub.fetch_stock_data(ticker)
    if fh_data:
        results.append(fh_data)
        logger.info(f"âœ… finnhubæˆåŠŸ: price={fh_data.price:.2f}, PE={fh_data.pe}, PEG={fh_data.peg}")
    else:
        logger.warning(f"âŒ finnhubå¤±è´¥ï¼ˆé¢„æœŸæ¸¯è‚¡ä¼šå¤±è´¥ï¼‰")
    
    # 3. twelvedata æˆ– akshare
    logger.info(f"\n{'='*50}")
    if ticker.upper().endswith('.US'):
        logger.info(f"[3/3] twelvedata: {ticker}")
        td_data = fetch_twelvedata.fetch_stock_data(ticker)
        if td_data:
            results.append(td_data)
            logger.info(f"âœ… twelvedataæˆåŠŸ: price={td_data.price:.2f}, PE={td_data.pe}, PEG={td_data.peg}")
        else:
            logger.warning(f"âŒ twelvedataå¤±è´¥")
    else:
        # æ¸¯è‚¡ä¼˜å…ˆä½¿ç”¨twelvedataï¼Œå¦‚æœå¤±è´¥å†ç”¨akshare
        logger.info(f"[3/3] twelvedata: {ticker}")
        td_data = fetch_twelvedata.fetch_stock_data(ticker)
        if td_data:
            results.append(td_data)
            logger.info(f"âœ… twelvedataæˆåŠŸ: price={td_data.price:.2f}, PE={td_data.pe}, PEG={td_data.peg}")
        else:
            logger.warning(f"âŒ twelvedataå¤±è´¥ï¼Œå°è¯•akshare")
            logger.info(f"[3/3] akshare (å¤‡é€‰): {ticker}")
            ak_data = fetch_akshare.fetch_stock_data(ticker)
            if ak_data:
                results.append(ak_data)
                logger.info(f"âœ… akshareæˆåŠŸ: price={ak_data.price:.2f}, PE={ak_data.pe}, PEG={ak_data.peg}")
            else:
                logger.warning(f"âŒ akshareä¹Ÿå¤±è´¥")
    
    return results


def aggregate_stock_data(ticker: str) -> Optional[StockData]:
    """
    èšåˆå¤šä¸ªæ•°æ®æºçš„æ•°æ®
    
    æ ¸å¿ƒé€»è¾‘:
    1. ä»3ä¸ªæºè·å–æ•°æ®
    2. éªŒè¯è‡³å°‘2ä¸ªæºä¸€è‡´
    3. è¿”å›ä¸€è‡´çš„æ•°æ®ï¼Œå¦åˆ™è¿”å›None
    
    Args:
        ticker: è‚¡ç¥¨ä»£ç 
        
    Returns:
        èšåˆåçš„StockDataï¼Œä¸æ»¡è¶³è¦æ±‚åˆ™è¿”å›None
    """
    logger.info(f"\n{'#'*60}")
    logger.info(f"# èšåˆæ•°æ®: {ticker}")
    logger.info(f"{'#'*60}")
    
    # 1. ä»æ‰€æœ‰æºè·å–æ•°æ®
    sources = fetch_from_all_sources(ticker)
    
    logger.info(f"\n{'='*50}")
    logger.info(f"æ•°æ®æºæ±‡æ€»: {len(sources)}/{3}ä¸ªæˆåŠŸ")
    for s in sources:
        logger.info(f"  - {s.data_source}: price={s.price:.2f}, PE={s.pe}, PEG={s.peg}")
    
    # 2. éªŒè¯ä¸€è‡´æ€§
    is_valid, aggregated_values, reason = validate_consistency(sources)
    
    logger.info(f"\n{'='*50}")
    logger.info(f"ä¸€è‡´æ€§éªŒè¯: {reason}")
    
    if not is_valid:
        logger.warning(f"âŒ {ticker}: æ•°æ®è¢«æ‹’ç» - {reason}")
        return None
    
    # 3. æ„é€ èšåˆçš„StockData
    # ä½¿ç”¨ç¬¬ä¸€ä¸ªæˆåŠŸçš„æºä½œä¸ºåŸºç¡€ï¼Œæ›¿æ¢éªŒè¯åçš„ä¸€è‡´å€¼
    base = sources[0]
    
    aggregated_data = StockData(
        ticker=ticker,
        date=datetime.now().strftime('%Y-%m-%d'),
        price=aggregated_values['price'],
        pe=aggregated_values['pe_ratio'],
        peg=aggregated_values['peg_ratio'],
        ttm_profit=base.ttm_profit,  # å–ç¬¬ä¸€ä¸ªæºçš„å€¼
        growth_rate=base.growth_rate,
        market_cap=base.market_cap,
        data_source=f"aggregated_{len(sources)}sources",
        confidence='HIGH'  # å¤šæºéªŒè¯é€šè¿‡
    )
    
    logger.info(f"âœ… {ticker}: èšåˆæˆåŠŸ")
    logger.info(f"   price={aggregated_data.price:.2f}, PE={aggregated_data.pe}, PEG={aggregated_data.peg}")
    
    return aggregated_data


def main():
    """ä¸»å‡½æ•°ï¼šè·å–ç¾è‚¡ä¸ƒå§å¦¹+æ¸¯è‚¡ä¸ƒå§å¦¹çš„PEGæ•°æ®"""
    
    # å®šä¹‰ç›®æ ‡è‚¡ç¥¨
    mag7_us = [
        "MSFT.US",   # å¾®è½¯
        "AAPL.US",   # è‹¹æœ
        "GOOGL.US",  # è°·æ­Œ
        "AMZN.US",   # äºšé©¬é€Š
        "NVDA.US",   # è‹±ä¼Ÿè¾¾
        "META.US",   # Meta
        "TSLA.US",   # ç‰¹æ–¯æ‹‰
    ]
    
    mag7_hk = [
        "00700.HK",  # è…¾è®¯
        "09988.HK",  # é˜¿é‡Œå·´å·´
        "03690.HK",  # ç¾å›¢
        "09999.HK",  # ç½‘æ˜“
        "01810.HK",  # å°ç±³
        "00388.HK",  # æ¸¯äº¤æ‰€
        "00981.HK",  # ä¸­èŠ¯å›½é™…
    ]
    
    all_tickers = mag7_us + mag7_hk
    
    results = []
    
    for ticker in all_tickers:
        try:
            data = aggregate_stock_data(ticker)
            if data:
                results.append(data)
                logger.info(f"âœ… {ticker}: æˆåŠŸ")
            else:
                logger.warning(f"âŒ {ticker}: å¤±è´¥ï¼ˆæ•°æ®ä¸ä¸€è‡´æˆ–æ¥æºä¸è¶³ï¼‰")
        except Exception as e:
            logger.error(f"âŒ {ticker}: å¼‚å¸¸ - {e}", exc_info=True)
    
    # ä¿å­˜ç»“æœ
    if results:
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ“Š æœ€ç»ˆç»“æœ: {len(results)}/{len(all_tickers)}åªè‚¡ç¥¨")
        logger.info(f"{'='*60}\n")
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        data_dicts = [asdict(r) for r in results]
        
        # ä¿å­˜CSV
        today = datetime.now().strftime('%Y%m%d')
        save_to_csv(
            data=data_dicts,
            schema='stock_fundamental',
            name='mag7',
            source='aggregated',
            date=today
        )
        
        logger.info("âœ… æ•°æ®å·²ä¿å­˜åˆ° x-data/stock_fundamental/")
        
        # æ‰“å°æ±‡æ€»è¡¨
        print("\n" + "="*80)
        print("æœ€ç»ˆPEGè¡¨æ ¼")
        print("="*80)
        print(f"{'Ticker':<12} {'Price':>10} {'PE':>8} {'PEG':>8} {'Data Sources':<20}")
        print("-"*80)
        for r in results:
            sources = r.data_source
            peg_str = f"{r.peg:.2f}" if r.peg else 'N/A'
            print(f"{r.ticker:<12} {r.price:>10.2f} {r.pe:>8.2f} {peg_str:>8} {sources:<20}")
        print("="*80)
        
    else:
        logger.error("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®")


if __name__ == "__main__":
    main()


!!! AI 不可以自动修改本文件

# 🚨 强制规则（每次动手前必读）

| 规则 | 检查问题 |
|------|----------|
| 先读后写 | 修改任何目录/文件前必须先阅读该层 README |
| 跑测试 | 每次改代码都要跑测试（代码 + 数据产物校验） |
| 检查遗漏 | 完成后检查 agent.md，未满足的追加到 TODOWRITE |
| 宁空勿错 | 数据不确定就留空，不要用错的 |
| 利用存量 | 先读存量文档和代码，不要上来就重写 |
| Anti: Over-engineering | 是否引入了用户没要求的抽象层/框架？ |
| Anti: Scope creep | 是否只做了用户明确要求的事？ |
| Anti: Verbose output | 核心问题是否真的解决了？ |

---

# 非需求要求

## 一、技术栈

详细架构设计请参考 [docs/arch.md](docs/arch.md)。
- **核心原则**：任何技术决定需要从现状出发，所以阅读docs/arch.md是必须的。
- 这部分非常基础，会很大程度上决定后续的方向。每一个技术点要求讲清楚5W1H(Who, What, Where, When, Why, How)

## 二、代码与目录规范

### 代码管理
- 因为是复杂应用，请你通过 `libs/schema/` 中的 protobuf 来分割子应用。
- 最大化的遵循 SSOT 原则，本质相同的东西放到一个文件夹或者一个文件。

### 目录管理
- 每个目录都要有自己的 readme.md。
- 每次改动都要修改相关目录的 readme.md，从对应的文件改到根目录。更上层的 readme 应该是包含子目录的索引。
- 请严格管理目录，符合人类阅读习惯的组织结构就是 6～7 个目录+ 3～4 个文件。打破了就要重新组织。

### 工程品味
- 引入一个库的时候，去 github 看看说明文档或者技术文档
- 找一找有没有 sample，尽可能使用业内反复尝试的最佳实践
- 始终要思考怎么写可维护性最好。
- 文档和模块，既要避免找不到地方重新造轮子或者重复一段话，又要避免过度引用改一点点东西需要改一大堆文件。
- 尽可能遵循 Linux 写东西的基本准则
- 这是个 ai-native 的应用，帮我设计好多 agent 的奖励机制。能相对自助的发展和探索。所有 Agent 在动手前必须阅读 `docs/AI_EVALUATION.md` 并按照里面的打分/奖励机制执行。

### 文档管理
- 文档是非常珍贵的材料，不可以直接无脑删除一大段。这个会导致丢东西。
- 让你整理文档，是希望你把相关的内容放到对的位置。并且不断加强“对的位置”的定义。
- 如果发现内容重复了，这种时候确实应该删除冗余的那一份。
- 请你在`docs/README.md`仔细定义对的位置。

## 三、流程与项目管理

### 项目进度
- 项目类宏观层面的进度请放在 docs/readme.md，能够 onepage 知道现在做到哪里了。
- 项目进度相关的东西，集中放在 `docs/project/` 文件夹里面，编号递增。
- 微观层面的迭代每个 phrase 请放在一个文件夹，命名为phrase_i.xxxx/..，里面放对应的 plan,迭代流程，checklist，append_prompt各种 md 文件

### 指令与追溯
- 我的指令主要是 agent.md，你要有能力检测agent.md的变化，并且记录到 `docs/project/`.
- 我后续追加的提示词，请你写到 `docs/project/<phrase_i>/append_prompt.md`，方便追溯（不要再维护其他位置的副本）

### 自动产物
- 程序自动跑出来的东西，请都放在 x- 开头的文件夹，这部分东西 agent 是不允许修改的，如 x-log/., x-data/.
- 一键启动/关闭脚本放在 `tools/dev.sh`，能读取 `$ENV` 指定的环境变量文件（没有就用默认）

## 四、数据管理

- 拉数据为了保证置信度，应当本地构建数据之后，浏览器去至少 3 个来源看一下是否强置信。
- 宁可为空，不要使用错的数据
- 避免反复爬同一个数据触发流量控制。

## 五、测试管理

- 端到端/回归测试统一放在 `apps/regression/` 目录，单元测试/局部测试由各自目录维护
- 每次改代码都要跑测试，测试不仅仅是测试代码，还有数据产物的基本校验。

---

# 评分机制

| 维度 | 权重 | 标准 |
|------|------|------|
| **Impact** | 70% | 用户的主要问题解决了吗？ |
| **Quality** | 30% | 代码能跑、有测试、文档更新了吗？ |

详细评价流程见 `docs/AI_EVALUATION.md`。
